{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再帰型ニューラルネットワークを用いたテキスト分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x129c67b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データの読み込みとモデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import MeCab\n",
    "tagger = MeCab.Tagger('-Owakati')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return tagger.parse(text)\n",
    "\n",
    "TEXT = torchtext.data.Field(sequential=True, batch_first=True, tokenize=tokenizer, lower=True, fix_length=100)\n",
    "LABEL = torchtext.data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自作のデータセットを用いる場合は，以下のコードを用いる．\n",
    "# このコードでは，data/my_text_dataset フォルダに，タブ区切りで「テキスト」と「ラベル」を\n",
    "# 1行に1組ずつ列挙した train.tsv および test.tsv のファイルがあることを想定している．\n",
    "# \n",
    "# **注意**：以降のコードでは，バッチ（変数名を data とする）のテキストやラベルを data.text や data.label として\n",
    "# アクセスしているが，TabularDataset クラスを用いる場合には，これを data.Text や data.Label と書き換えること．\n",
    "# 2020年6月24日時点で，torchtextの中で変数名が一貫していないようである．\n",
    "# 書き換えないと `'Batch' object has no attribute 'text'` というエラーが出る．\n",
    "\n",
    "train, test = torchtext.data.TabularDataset.splits(path='.',\n",
    "                                         train='train.tsv', test='test.tsv', format='tsv',\n",
    "                                         fields=[('Text', TEXT), ('Label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, max_size=25000)\n",
    "# 事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを用いる．\n",
    "# TEXT.build_vocab(train, vectors=\"glove.6B.100d\")\n",
    "\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('<unk>', 0), ('others', 1), ('sports', 2)])\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<unk>', 0), ('<pad>', 1), (' ', 2), ('の', 3), ('、', 4), ('い', 5), ('と', 6), ('に', 7), ('ー', 8), ('で', 9), ('た', 10), ('て', 11), ('る', 12), ('し', 13), ('。', 14), ('な', 15), ('は', 16), ('が', 17), ('を', 18), ('ン', 19)]\n",
      "2739\n"
     ]
    }
   ],
   "source": [
    "print(list(TEXT.vocab.stoi.items())[:20])\n",
    "print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "trainloader, testloader = torchtext.data.BucketIterator.splits((train, test), batch_size=4, sort=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【   s p o r t s   w a t c h   】   ダ ル ビ ッ シ ュ   と   川 崎   宗   、   試 合   後   に   ツ イ ッ タ ー   で   激 励   北 海 道   日 本   ハ ム フ ァ イ タ ー ズ   の   エ ー ス ・ ダ ル ビ ッ シ ュ   有   と   、   福 岡   ソ フ ト バ ン ク ホ ー ク ス  \n",
      "【   s p o r t s   w a t c h   】   興   毅   の   敗 戦   に   ジ ョ ー ジ   ＆   テ リ ー   は   「   勉 強   に   な っ   た   と   思 う   」   w b c   世 界   フ ラ イ   級   王 座   統 一   戦   で   は   、   暫 定   王 者   ポ ン サ ク レ ッ ク\n",
      "気   を   つ け   て   ！   　   ス マ ー ト   フ ォ ン   、   海 外   パ ケ ッ ト   定 額   プ ラ ン   の   つ も り   が   約   1 0 0   万   円   ！   の   ナ ゾ   【   話 題   】   歩 行   者   に   あ ま り   出 会 わ   な い   街   、   し か も   言 葉  \n",
      "【   s p o r t s   w a t c h   】   興   毅   が   成 長   ア ピ ー ル   「   1 0   段 階   で   言 う   た ら   ま だ   3   か   3   ,   5   」   プ ロ   ボ ク サ ー   ・   亀 田   興   毅   が   、   か ね て か ら   語 っ   て   い   た   “  \n",
      "['sports', 'sports', 'others', 'sports']\n"
     ]
    }
   ],
   "source": [
    "data = dataiter.__next__()\n",
    "x, y = data.Text, data.Label\n",
    "for x_i in x:\n",
    "    print(' '.join(TEXT.vocab.itos[w] for w in x_i))\n",
    "print([LABEL.vocab.itos[yi] for yi in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        hn = hn.squeeze(0)\n",
    "        return self.fc(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 187.5182\n",
      "epoch: 1, loss: 159.5307\n",
      "epoch: 2, loss: 150.9242\n",
      "epoch: 3, loss: 146.5221\n",
      "epoch: 4, loss: 143.6548\n",
      "epoch: 5, loss: 141.7055\n",
      "epoch: 6, loss: 139.8902\n",
      "epoch: 7, loss: 138.4223\n",
      "epoch: 8, loss: 136.8523\n",
      "epoch: 9, loss: 135.6241\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "rnn = RNN(len(TEXT.vocab), 100, 30, 3)\n",
    "# 事前学習済みの単語埋め込みベクトルを用いる場合は，以下のコードを挿入する．\n",
    "# rnn.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "rnn.to(device)\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.01)\n",
    "for epoch in range(10):\n",
    "    sumloss = 0.0\n",
    "    #for data in trainloader:  （計算資源が十分ある環境では，全てのデータを使う方が良い）\n",
    "    for data in islice(trainloader, 250):\n",
    "        x, y = data.Text, data.Label - 1\n",
    "        optimizer.zero_grad()\n",
    "        a = rnn(x)\n",
    "        loss = F.cross_entropy(a, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sumloss += loss.item()\n",
    "    print('epoch: {}, loss: {:.4f}'.format(epoch, sumloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x, y = data.Text, data.Label - 1\n",
    "        a = rnn(x)\n",
    "        pred_y = torch.argmax(a, dim=1)\n",
    "        correct += (pred_y == y).sum().item()\n",
    "        total += pred_y.size(0)\n",
    "\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【   s p o r t s   w a t c h   】   ノ ム   さ ん   、   楽 天   新   監 督   に   「   な ん で   星 野   な   の   」   9   日   深 夜   、   t b s   の   ス ポ ー ツ   番 組   「   s   1   」   で   は   、   元   東 北   楽 天   ゴ ー ル デ ン\n",
      "【   s p o r t s   w a t c h   】   闘 莉   王   、   ド イ ツ   w   杯   時   は   「   自 分   に   イ ラ イ ラ   し   て   た   」   日 本 テ レ ビ   「   n e w s   z e r o   」   （   2 3   日   放 送   分   ）   で   は   、   日 本   代\n",
      "【   s p o r t s   w a t c h   】   韓 国   ・   全   北   サ ポ ー タ ー   が   卑 劣   な   横 断 幕   、   セ レ ッ ソ   は   悔 や ま   れ る   敗 戦   韓 国   の   全   州   で   行 わ   れ   た   、   ア ジ ア   ・   チ ャ ン ピ オ ン ズ   リ ー グ  \n",
      "「   直 訳   か   よ   」   m l b   日 本   開 幕   戦   の   動 画   が   話 題   に   e s p n   ア メ リ カ   が   制 作   し   た   動 画   が   話 題   に   な っ   て   い る   。   動 画   は   、   m l b   日 本   開 幕   戦   「   マ リ ナ ー ズ\n",
      "['others', 'others', 'others', 'sports']\n",
      "['sports', 'sports', 'sports', 'sports']\n"
     ]
    }
   ],
   "source": [
    "data = dataiter.__next__()\n",
    "x, y = data.Text, data.Label\n",
    "for x_i in x:\n",
    "    print(' '.join(TEXT.vocab.itos[w] for w in x_i))\n",
    "a = rnn(x)\n",
    "pred_y = torch.argmax(a, dim=1)\n",
    "print([LABEL.vocab.itos[yi + 1] for yi in pred_y])\n",
    "print([LABEL.vocab.itos[yi] for yi in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
